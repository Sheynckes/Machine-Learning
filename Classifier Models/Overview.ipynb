{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类算法的选择\n",
    "\n",
    "由于每个算法都基于某些特定的假设，且均含有某些缺点，因此需要通过大量的实践为特定的问题选择合适的算法。根据**“没有免费午餐”**理论：没有任何一种分类器可以在所有可能的应用场景下都有良好的表现。实践证明，只有比较了多种学习算法的性能，才能为特定问题挑选出最合适的模型。这些模型针对不同数量的特征或者样本、数据集中的噪声数量，以及类别是否线性可分等问题时，表现各不相同。\n",
    "\n",
    "总而言之，分类器的性能、计算能力和预测能力，在很大程度上都依赖于用于模型训练的相关数据。训练机器学习算法所涉及的五个主要步骤可以概述如下：\n",
    "\n",
    "- 特征的选择\n",
    "- 确定模型性能的评价标准\n",
    "- 选择分类器及其优化算法\n",
    "- 对模型性能进行评估\n",
    "- 算法调优\n",
    "\n",
    "对于每一种分类算法，需要掌握以下内容：\n",
    "\n",
    "- 该算法的基本概念\n",
    "- 特征选择、预处理和模型性能的评价标准\n",
    "- 选择和使用该算法时需要注意的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数化模型与非参数化模型\n",
    "\n",
    "机器学习算法可以划分为参数化模型和非参数化模型。\n",
    "\n",
    "- 参数化模型需要我们通过训练数据对参数进行估计，并通过学习得到一个模式，以便在无需原始训练数据信息的情况下对新的数据点进行分类操作。典型的参数化模型包括：感知器、逻辑斯谛回归和线性支持向量机等。\n",
    "- 非参数化模型无法通过一组固定的参数来进行表征，而且其参数的数量也会随着训练数据的增加而递增；此类模型的特点是会对训练数据进行记忆，典型的非参数化模型包括：决策树、随机森林、核SVM、KNN。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
